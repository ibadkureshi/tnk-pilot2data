{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track&Know Pilot 2 Synthetic Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgement\n",
    "\n",
    "![\"Funded by EU logo\"](https://github.com/ibadkureshi/tnk-locationallocation/raw/master/docs/images/EU-H2020.jpg \"Funded by EU H2020\") This project has received funding from the European Unionâ€™s Horizon 2020 research and innovation programme under grant agreement No 780754."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates a synthetic dataset of patient appointments and referrals to a fictional service in the North East of England. The code can be adjusted to incorporate any area on mainland Great Britain. NI or the islands can be integrated too, however the structure of postcode, GP and OSA public data is different, and data input handlers will need to be adjusted.\n",
    "\n",
    "The behaviour of the patients (visiting their nearby GP followed by attending a specialist clinic), appointments (clinic appointments within 7day-6weeks of the referral (gp appointment)), and facilities (one major facility taking the load, along with minor facilities) is meant to mirror the real data used under Pilot 2 of the Track & Know Project.\n",
    "\n",
    "Real postcodes, from Roayl Mail, are used to generate the appointment population, real facilities are used based on the British Lung Foundations study of Obstructive Sleep Apnea, and real GP's are used based on public data from the NHS. \n",
    "\n",
    "**All data is randomly generated and changes with every run of the generation code. Any resemblance to actual events or locales or persons, living or dead, is entirely coincidental.**\n",
    "\n",
    "This data differs from the original data in that postcodes from the catchment are randomly selected. There were patterns in the occurrences of OSA and the referral schedules within the real data that are not reproduced in this synthetic dataset. These patterns are not reproduced because reapplication of this code (w/ the pattern reproduction) on the Track&Know pilot catchment area *could* lead to an exposure of actual patients.\n",
    "\n",
    "Please read the 'Variable Operationalisation' document for more information about the output of this code.\n",
    "\n",
    "Please refer to the Track&Know website for more information about the project and Pilot 2. https://trackandknowproject.eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "from geopy.distance import geodesic\n",
    "from dateutil.rrule import DAILY, rrule, MO, TU, WE, TH, FR\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a geographic bounding box to map out area of interest where the points need to reside "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LowerLeft = [53.594777, -3.732939]\n",
    "UpperRight = [54.976496, -2.439935]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is only required if you want to visualise the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import folium\n",
    "#\n",
    "#m = folium.Map(location=[(LowerLeft[0]+UpperRight[0])/2,(LowerLeft[1]+UpperRight[1])/2], tiles='cartodbpositron', zoom_start=8)\n",
    "#folium.Rectangle(\n",
    "#    bounds=[LowerLeft, UpperRight],\n",
    "#    popup='Area of Interest',\n",
    "#    color='crimson',\n",
    "#    fill=False,\n",
    "#).add_to(m)\n",
    "\n",
    "#m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPatients = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set is a synthetic dataset of patients for an imaginary Obstructive Sleep Apnea service. Using the British Lung Foundations data and propensity maps, we identify facilities that exist in our area of interest. ***This is a manual process and would need to be adjusted if the area of interest changes***. The map can be found here\n",
    "https://www.blf.org.uk/sites/default/files/BLF_OSA_Map_A4_UK_Overall_Weighted_Clinics_0.pdf\n",
    "\n",
    "To replicate the observed behaviour in Track&Know's Pilot 2, we are identifying a primary centre and a set of outreach clinics. As it happens the BLF data highlights that this area of interest has 1 major centre and 4 minor centres. So the first row is the major centre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Facilities in area of interest](imgs/facilities.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "facilities = [\n",
    "    ['Blackpool Victoria Hospital','FY3 8NR','53.820777','-3.013842'],\n",
    "    ['Furness General Hospital','LA14 4LF','54.136862','-3.208707'],\n",
    "    ['Westmoorland General Hospital','LA9 7RG','54.307665','-2.732336'],\n",
    "    ['Royal Lancaster Infirmary','LA1 4RP','54.042097','-2.798714'],\n",
    "    ['Royal Blackburn Hospital','BB2 3HH','53.734792','-2.460098']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postcodes and Residential Areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the UK Postcodes to Lat/Long. Both the full list and the list of outcodes is required. These can be found here:\n",
    "https://www.freemaptools.com/download-uk-postcode-lat-lng.htm\n",
    "Retain the master list of postcodes, but also create a new dataframe with only those postcodes inside the area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes = pd.read_csv('input/ukpostcodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = postcodes[(postcodes.latitude >= LowerLeft[0]) & (postcodes.latitude <= UpperRight[0])]\n",
    "postcodePool = i[(i.longitude >= LowerLeft[1]) & (i.longitude <= UpperRight[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short listing general practitioners (GPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the list of GP's available from the NHS. This data is not in the bundle but can be found here:\n",
    "https://digital.nhs.uk/services/organisation-data-service/data-downloads/gp-and-gp-practice-related-data\n",
    "As there are no headers in the file, we add names to those columns that are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps = pd.read_csv('input/epraccur.csv', names = [\"ident\",\"name\",\"a\",\"b\",\"location\",\"street\",\"town\",\"district\",\"c\",\"postcode\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to merge the GP dataframe with the postcode dataframe - this gives lat/lon pairs to the GP addresses. And then create a shortlist of GP's that are in our area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_merge(df1, df2, index, columns):\n",
    "    #merging to dataframes (original dataset + postcodes)\n",
    "    df = df1.merge(df2, on=index, how='inner')\n",
    "    df = pd.concat([df[column] for column in columns], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=selective_merge(postcodes, gps, 'postcode', \n",
    "                             ['ident','name','town','postcode','latitude','longitude'])\n",
    "i = x[((x.latitude >= LowerLeft[0]) & (x.latitude <= UpperRight[0]))]\n",
    "gpPool = i[(i.longitude >= LowerLeft[1]) & (i.longitude <= UpperRight[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is only required if you want to visualise the GP's. Please note the folium box above needs to be uncommented too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0,len(gpPool)):\n",
    "#    folium.Marker([gpPool.iloc[i]['latitude'],gpPool.iloc[i]['longitude']]).add_to(m)\n",
    "#m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Generation of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appointment Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the rrule function to generate a table of workdays for the interested time period. Epoch times are used and this generator is working from 01 January 2020 till 31 December 2020. The code doesnt account for public holidays but this can be reached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AppointDates = rrule(DAILY, dtstart=dt.fromtimestamp(1546333200), until=dt.fromtimestamp(1577782800), byweekday=(MO,TU,WE,TH,FR), count=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of facilities is an order of magnitude we and we need to send more apointments to the major centre we create a list (the size of the number of patients) where there each item is 50-50 major or all (minor+major). In the all allocation its a 1 in X chance (where X is the number of facilities defined above) for a facility to be selected. In this example with 5 facilities the split will be 60-10-10-10-10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "possibleFacilities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,numPatients):\n",
    "    if random.randint(0,1):\n",
    "        possibleFacilities.append(facilities[random.randint(0,4)])\n",
    "    else:\n",
    "        possibleFacilities.append(facilities[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient Appointments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we go 1-by-1 creating patients by randomly selecting a postcode from our pool of relavent postcodes. Selection of a postcode does not remove it from the pool i.e. you can have multiple patients from the same. \n",
    "We then identify the nearest GP as per catchment rules your GP is usually the closest one. \n",
    "We start allocating an appointment date by identifying the average appointments per day and incrementing the counter based on that. i.e. if 40 is the average appointments/day then the first 40 appointments are allocated on day 1 and then next 40 on day 2.\n",
    "Finally we calculate the appointment date of the actual OSA clinic by adding on a random value between 7-42 days (6 weeks is the SLA). \n",
    "The patient record is then added to the dataset incorporating the corresponding row of which facility the appointment is held in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataArray = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,numPatients):\n",
    "    # Generate a random number to pick a postcode for this patient (i.e. postcode lottery)\n",
    "    index = random.randint(0,len(postcodePool)-1)\n",
    "    lat = postcodePool.iloc[index]['latitude']\n",
    "    lon = postcodePool.iloc[index]['longitude']\n",
    "\n",
    "    # identify the closest gp - find the shortest distance between the patients residence and GP's from the pool\n",
    "    closestGP = []\n",
    "    for j in range(0,len(gpPool)):\n",
    "        glat = gpPool.iloc[j]['latitude']\n",
    "        glon = gpPool.iloc[j]['longitude']\n",
    "        distance = geodesic([lat,lon], [glat,glon]).m\n",
    "        \n",
    "        currentGP = [distance, gpPool.iloc[j]['name'], gpPool.iloc[j]['postcode'], glat, glon]\n",
    "        if closestGP == []:\n",
    "            closestGP.append(currentGP)\n",
    "        else:\n",
    "            if closestGP[0][0] > distance:\n",
    "                closestGP.pop(0)\n",
    "                closestGP.append(currentGP)\n",
    "\n",
    "    # Identify the appointment date - this is done by averaging the number of referrals per day\n",
    "    # we find the average by dividing the number of synthetic patients with the number of working\n",
    "    # days. While in the original dataset there is some fluctuation on new referrals becuase most\n",
    "    # patients are on followup assuming an average is OK. Then calculate based on referral date\n",
    "    # the likely clinic date - between 7days to 6 weeks.\n",
    "    maxPatients = int(numPatients/len(list(AppointDates)))+2 # to ensure there are no round down errors\n",
    "    gpAppoint = AppointDates[int(i/maxPatients)].strftime('%d/%m/%Y')\n",
    "    clinicAppoint = (AppointDates[int(i/maxPatients)] + timedelta(days=random.randint(7,42))).strftime('%d/%m/%Y')\n",
    "    \n",
    "    # Merge all values together and append to record.\n",
    "    payload = [i,postcodePool.iloc[index]['postcode'],lat,lon, \n",
    "               gpAppoint,closestGP[0][1],closestGP[0][2],closestGP[0][3],closestGP[0][4], \n",
    "               clinicAppoint,possibleFacilities[i][0],possibleFacilities[i][1],possibleFacilities[i][2],possibleFacilities[i][3]]\n",
    "    dataArray.append(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master Record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out the master appointment log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientAppointmentLog = pd.DataFrame(dataArray,columns=[\n",
    "    'patientno','postcode','latitude','longitude',\n",
    "    'gpdate','gpname','gppostcode','gplatitude','gplongitude',\n",
    "    'clinicdate','clinicname','clinicpostcode','cliniclatitude','cliniclongitude'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientAppointmentLog.to_csv('output/appointmentlog.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demand Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file just contains lat/lon and id columns to simplify location allocation work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = open('output/demandfile.csv','w')\n",
    "for i in range(0, len(dataArray)):\n",
    "    data = [str(dataArray[i][2]),str(dataArray[i][3]),str(dataArray[i][0])] \n",
    "    print(','.join(data),file=w)\n",
    "w.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
